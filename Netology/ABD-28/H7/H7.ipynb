{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практика с лекции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      " 22 60302   22 13710    0     0  30515      0  0:00:01 --:--:--  0:00:01 30534\n",
      "100 60302  100 60302    0     0   120k      0 --:--:-- --:--:-- --:--:--  120k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: titanic.csv\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv -O titanic.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('titanic.csv', inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|null|    0|    0|          330877| 8.4583| null|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| null|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| null|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| null|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| null|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| null|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| null|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| null|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| null|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|null|    0|    0|          244373|   13.0| null|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| null|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|null|    0|    0|            2649|  7.225| null|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.select('Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|\n",
      "+--------+------+------+----+-------+--------+\n",
      "|       0|     3|  male|22.0|   7.25|       S|\n",
      "|       1|     1|female|38.0|71.2833|       C|\n",
      "|       1|     3|female|26.0|  7.925|       S|\n",
      "|       1|     1|female|35.0|   53.1|       S|\n",
      "|       0|     3|  male|35.0|   8.05|       S|\n",
      "+--------+------+------+----+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|   77|\n",
      "|    null|    2|\n",
      "|       C|  168|\n",
      "|       S|  644|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.groupBy('Embarked').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------+------------------+-----------------+--------+\n",
      "|summary|           Survived|            Pclass|   Sex|               Age|             Fare|Embarked|\n",
      "+-------+-------------------+------------------+------+------------------+-----------------+--------+\n",
      "|  count|                891|               891|   891|               714|              891|     889|\n",
      "|   mean| 0.3838383838383838| 2.308641975308642|  null| 29.69911764705882| 32.2042079685746|    null|\n",
      "| stddev|0.48659245426485753|0.8360712409770491|  null|14.526497332334035|49.69342859718089|    null|\n",
      "|    min|                  0|                 1|female|              0.42|              0.0|       C|\n",
      "|    max|                  1|                 3|  male|              80.0|         512.3292|       S|\n",
      "+-------+-------------------+------------------+------+------------------+-----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_filtered.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_filtered.na.fill({'Age':30,'Embarked':'S'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(inputCol='Sex', outputCol='SexInd')\n",
    "indexerTrained = indexer.fit(df_filtered)\n",
    "df_upd = indexerTrained.transform(df_filtered)\n",
    "\n",
    "indexer = StringIndexer(inputCol='Embarked', outputCol='EmbarkedInd')\n",
    "indexerTrained = indexer.fit(df_upd)\n",
    "df_upd = indexerTrained.transform(df_upd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot = OneHotEncoder(inputCol='EmbarkedInd', outputCol='EmbarkedOhe')\n",
    "onehotTrained = onehot.fit(df_upd)\n",
    "df_upd = onehotTrained.transform(df_upd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+------+-----------+-------------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|SexInd|EmbarkedInd|  EmbarkedOhe|\n",
      "+--------+------+------+----+-------+--------+------+-----------+-------------+\n",
      "|       0|     3|  male|22.0|   7.25|       S|   0.0|        0.0|(2,[0],[1.0])|\n",
      "|       1|     1|female|38.0|71.2833|       C|   1.0|        1.0|(2,[1],[1.0])|\n",
      "|       1|     3|female|26.0|  7.925|       S|   1.0|        0.0|(2,[0],[1.0])|\n",
      "|       1|     1|female|35.0|   53.1|       S|   1.0|        0.0|(2,[0],[1.0])|\n",
      "|       0|     3|  male|35.0|   8.05|       S|   0.0|        0.0|(2,[0],[1.0])|\n",
      "+--------+------+------+----+-------+--------+------+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_upd.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=['Pclass','Age','Fare','SexInd','EmbarkedOhe'], outputCol='Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-------+--------+------+-----------+-------------+--------------------+\n",
      "|Survived|Pclass|   Sex| Age|   Fare|Embarked|SexInd|EmbarkedInd|  EmbarkedOhe|            Features|\n",
      "+--------+------+------+----+-------+--------+------+-----------+-------------+--------------------+\n",
      "|       0|     3|  male|22.0|   7.25|       S|   0.0|        0.0|(2,[0],[1.0])|[3.0,22.0,7.25,0....|\n",
      "|       1|     1|female|38.0|71.2833|       C|   1.0|        1.0|(2,[1],[1.0])|[1.0,38.0,71.2833...|\n",
      "|       1|     3|female|26.0|  7.925|       S|   1.0|        0.0|(2,[0],[1.0])|[3.0,26.0,7.925,1...|\n",
      "|       1|     1|female|35.0|   53.1|       S|   1.0|        0.0|(2,[0],[1.0])|[1.0,35.0,53.1,1....|\n",
      "|       0|     3|  male|35.0|   8.05|       S|   0.0|        0.0|(2,[0],[1.0])|[3.0,35.0,8.05,0....|\n",
      "+--------+------+------+----+-------+--------+------+-----------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_upd = assembler.transform(df_upd)\n",
    "df_upd.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Взять данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master('local[*]').getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузить в PySpark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+-----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|variety_num|\n",
      "+------------+-----------+------------+-----------+-------+-----------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|          0|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|          0|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|          0|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|          0|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|          0|\n",
      "+------------+-----------+------------+-----------+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('iris.CSV', header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-------------------+------------------+------------------+---------+------------------+\n",
      "|summary|      sepal_length|        sepal_width|      petal_length|       petal_width|  variety|       variety_num|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+------------------+\n",
      "|  count|               150|                150|               150|               150|      150|               150|\n",
      "|   mean| 5.843333333333335|  3.057333333333334|3.7580000000000027| 1.199333333333334|     null|               1.0|\n",
      "| stddev|0.8280661279778637|0.43586628493669793|1.7652982332594662|0.7622376689603467|     null|0.8192319205190406|\n",
      "|    min|               4.3|                2.0|               1.0|               0.1|   Setosa|                 0|\n",
      "|    max|               7.9|                4.4|               6.9|               2.5|Virginica|                 2|\n",
      "+-------+------------------+-------------------+------------------+------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### При помощи VectorAssembler преобразовать все колонки с признаками в одну (использовать Pipeline — опционально)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|variety_num|         Features|\n",
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+\n",
      "|         5.1|        3.5|         1.4|        0.2| Setosa|          0|[5.1,3.5,1.4,0.2]|\n",
      "|         4.9|        3.0|         1.4|        0.2| Setosa|          0|[4.9,3.0,1.4,0.2]|\n",
      "|         4.7|        3.2|         1.3|        0.2| Setosa|          0|[4.7,3.2,1.3,0.2]|\n",
      "|         4.6|        3.1|         1.5|        0.2| Setosa|          0|[4.6,3.1,1.5,0.2]|\n",
      "|         5.0|        3.6|         1.4|        0.2| Setosa|          0|[5.0,3.6,1.4,0.2]|\n",
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "pl = Pipeline(stages=[VectorAssembler(inputCols=['sepal_length','sepal_width','petal_length','petal_width'], outputCol='Features')])\n",
    "plTrained = pl.fit(df)\n",
    "df_transf = plTrained.transform(df)\n",
    "df_transf.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбить данные на train и test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df_transf.randomSplit([0.8,0.2], seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создать модель логистической регреcсии или модель дерева и обучить её.\n",
    "Воспользоваться MulticlassClassificationEvaluator для оценки качества на train и test множестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Решил сделать обе\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+--------------------+--------------------+----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|variety_num|         Features|       rawPrediction|         probability|prediction|\n",
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+--------------------+--------------------+----------+\n",
      "|         4.4|        3.0|         1.3|        0.2| Setosa|          0|[4.4,3.0,1.3,0.2]|[54.8316731860621...|[1.0,5.8045981223...|       0.0|\n",
      "|         4.6|        3.2|         1.4|        0.2| Setosa|          0|[4.6,3.2,1.4,0.2]|[59.0189684197576...|[1.0,1.7180006172...|       0.0|\n",
      "|         4.6|        3.6|         1.0|        0.2| Setosa|          0|[4.6,3.6,1.0,0.2]|[76.5905029625326...|[1.0,1.3749820140...|       0.0|\n",
      "|         4.8|        3.1|         1.6|        0.2| Setosa|          0|[4.8,3.1,1.6,0.2]|[52.2432095666216...|[1.0,1.6438217837...|       0.0|\n",
      "|         4.9|        3.1|         1.5|        0.1| Setosa|          0|[4.9,3.1,1.5,0.1]|[55.1241026366712...|[1.0,8.6037985351...|       0.0|\n",
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(featuresCol='Features', labelCol='variety_num')\n",
    "lrTrained = lr.fit(train)\n",
    "df_train = lrTrained.transform(train)\n",
    "df_test = lrTrained.transform(test)\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "ev = MulticlassClassificationEvaluator(labelCol='variety_num')\n",
    "ev.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9841269841269842"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(df_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+--------------+-------------+----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|variety|variety_num|         Features| rawPrediction|  probability|prediction|\n",
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+--------------+-------------+----------+\n",
      "|         4.4|        3.0|         1.3|        0.2| Setosa|          0|[4.4,3.0,1.3,0.2]|[39.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|         4.6|        3.2|         1.4|        0.2| Setosa|          0|[4.6,3.2,1.4,0.2]|[39.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|         4.6|        3.6|         1.0|        0.2| Setosa|          0|[4.6,3.6,1.0,0.2]|[39.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|         4.8|        3.1|         1.6|        0.2| Setosa|          0|[4.8,3.1,1.6,0.2]|[39.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "|         4.9|        3.1|         1.5|        0.1| Setosa|          0|[4.9,3.1,1.5,0.1]|[39.0,0.0,0.0]|[1.0,0.0,0.0]|       0.0|\n",
      "+------------+-----------+------------+-----------+-------+-----------+-----------------+--------------+-------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol='Features', labelCol='variety_num')\n",
    "dtTrained = dt.fit(train)\n",
    "df_train = dtTrained.transform(train)\n",
    "df_test = dtTrained.transform(test)\n",
    "df_test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9920613938459278"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.evaluate(df_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46d9769e4a03f9c8a0d013aecc28fbd7cd74358c3b1961e5530525279813198c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
